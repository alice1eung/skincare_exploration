{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Data Exploration on the asian beauty subreddit.  I will be exploring the posts asking for recommendations for products for specific skin types and exploring which products are the most recommended in the comments/replies section. \n",
    "\n",
    "I will specifically be looking at a few threads where the comments are structured since it is difficult to extract data from unstructured posts.  A future next step is to look into phrase mining research done by the University of Illinois or named entity recongition with a Stanford package to look at unstructured posts and significantly expand the quantity of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary packages.  I initially had trouble importing praw because the notebook was running a different Python than the one in my command prompt so it could not find the import.  I fixed it by checking sys.executable and sys.path to see where the notebook is looking for imports and did path -m pip install praw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! usr/bin/env python3\n",
    "import sys\n",
    "import praw\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import string\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the Reddit API. I am looking at /r/AsianBeauty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='14_CHARS_IDENTIFIER', \n",
    "                     client_secret='27_CHARS_SECRET_ID', \n",
    "                     user_agent='SCRIPT_NAME', \n",
    "                     username='REDDIT_USER_NAME', \n",
    "                     password='REDDIT_LOGIN_PASSWORD')\n",
    "\n",
    "asian_beauty=reddit.subreddit('AsianBeauty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the Data from a few posts where the comments are structured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\"id\" : [],\n",
    "        \"product\" : [], \n",
    "        \"step\" : [],\n",
    "        \"opinion\" : [],\n",
    "        \"thoughts\" : [],\n",
    "        \"thread\": []\n",
    "}\n",
    "\n",
    "submission = reddit.submission(id = '6lmzyl')\n",
    "\n",
    "for comment in submission.comments:\n",
    "    if(len(comment.body.split(\"\\n\\n\")) >= 4 and comment.body[0] == \"*\"):\n",
    "        dict[\"id\"].append(comment.id)\n",
    "        dict[\"product\"].append(comment.body.split(\"\\n\\n\")[0].replace(\"**\",\"\"))\n",
    "        dict[\"step\"].append(comment.body.split(\"\\n\\n\")[1].replace(\"**\",\"\"))\n",
    "        dict[\"opinion\"].append(comment.body.split(\"\\n\\n\")[2].replace(\"**\",\"\"))\n",
    "        dict[\"thoughts\"].append(comment.body.split(\"\\n\\n\")[3].replace(\"**\",\"\"))  \n",
    "        dict[\"thread\"].append(\"Oily\")\n",
    "       \n",
    "submission = reddit.submission(id = '6na9hw')\n",
    "for comment in submission.comments:\n",
    "    if(len(comment.body.split(\"\\n\\n\")) >= 4):\n",
    "        dict[\"id\"].append(comment.id)\n",
    "        dict[\"product\"].append(comment.body.split(\"\\n\\n\")[0].replace(\"**\",\"\"))\n",
    "        dict[\"step\"].append(comment.body.split(\"\\n\\n\")[1].replace(\"**\",\"\"))\n",
    "        dict[\"opinion\"].append(comment.body.split(\"\\n\\n\")[2].replace(\"**\",\"\"))\n",
    "        dict[\"thoughts\"].append(comment.body.split(\"\\n\\n\")[3].replace(\"**\",\"\"))  \n",
    "        dict[\"thread\"].append(\"Dry\")\n",
    "        \n",
    "submission = reddit.submission(id = '6uijtv')\n",
    "for comment in submission.comments:\n",
    "    if(len(comment.body.split(\"\\n\\n\")) >= 4):\n",
    "        dict[\"id\"].append(comment.id)\n",
    "        dict[\"product\"].append(comment.body.split(\"\\n\\n\")[0].replace(\"**\",\"\"))\n",
    "        dict[\"step\"].append(comment.body.split(\"\\n\\n\")[1].replace(\"**\",\"\"))\n",
    "        dict[\"opinion\"].append(comment.body.split(\"\\n\\n\")[2].replace(\"**\",\"\"))\n",
    "        dict[\"thoughts\"].append(comment.body.split(\"\\n\\n\")[3].replace(\"**\",\"\"))  \n",
    "        dict[\"thread\"].append(\"Combination\")\n",
    "        \n",
    "submission = reddit.submission(id = '6remns')\n",
    "for comment in submission.comments:\n",
    "    if(len(comment.body.split(\"\\n\\n\")) >= 4):\n",
    "        dict[\"id\"].append(comment.id)\n",
    "        dict[\"product\"].append(comment.body.split(\"\\n\\n\")[0].replace(\"**\",\"\"))\n",
    "        dict[\"step\"].append(comment.body.split(\"\\n\\n\")[1].replace(\"**\",\"\"))\n",
    "        dict[\"opinion\"].append(comment.body.split(\"\\n\\n\")[2].replace(\"**\",\"\"))\n",
    "        dict[\"thoughts\"].append(comment.body.split(\"\\n\\n\")[3].replace(\"**\",\"\"))  \n",
    "        dict[\"thread\"].append(\"Acne\")\n",
    "        \n",
    "data = pd.DataFrame(dict)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiemnting on how to get a comment forest (the replies to a comment).  Since there are only 54 items in the list and I want to be able to quantify the popularity of a product by applying sentiment analysis on the comments to see if it's a positive comment or negative. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "for comment in submission.comments:\n",
    "    comment.refresh()\n",
    "    for reply in comment.replies:\n",
    "        print(reply.body)\n",
    "        ss = sid.polarity_scores(reply.body)\n",
    "        for k in ss:\n",
    "            print( \"{0}: {1},\" .format(k, ss[k]), end=\" \")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the sentiment analyzer seems to work quite well! I'm going to add a positive count and negative count column to the data set to record the comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "data[\"pos_count\"] = 0\n",
    "data[\"neg_count\"] = 0\n",
    "data[\"neu_count\"] = 0\n",
    "count_row = len(data)\n",
    "\n",
    "for i in range(0,count_row): \n",
    "    comment = reddit.comment(data['id'].iloc[i])\n",
    "    comment.refresh()\n",
    "    #print(comment.body)\n",
    "    for reply in comment.replies:\n",
    "        #print(reply.body)\n",
    "        ss = sid.polarity_scores(reply.body)\n",
    "        \n",
    "        if ss[\"compound\"] == 0.0:\n",
    "            #print(\"neutral\")\n",
    "            data.loc[i, \"neu_count\" ] += 1\n",
    "        elif ss[\"compound\"] > 0.0:\n",
    "            #print(\"postive\")\n",
    "            data.loc[i, \"pos_count\" ] += 1\n",
    "        else:\n",
    "            #print(\"neg\")\n",
    "            data.loc[i, \"neg_count\" ] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: x.str.lower() if(x.dtype == 'object') else x)\n",
    "\n",
    "data.loc[data['opinion'].str.contains(\"best\"), 'pos_count'] = data['pos_count'] + 1\n",
    "data.loc[data['opinion'].str.contains(\"worst\"), 'pos_count'] = data['pos_count'] + 1\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"skincare.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
